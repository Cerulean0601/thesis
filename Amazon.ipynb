{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2a4755",
   "metadata": {},
   "source": [
    "The [dataset](https://jmcauley.ucsd.edu/data/amazon_v2/index.html) is metadata for Magazine Subscriptions category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3922f187-f704-4399-97eb-3db8aaad7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "DIR_PATH = \"\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/dirve\")\n",
    "    DIR_PATH = r\"/content/dirve/MyDrive/研究所/Data/dblp/\"\n",
    "    sys.path.append('/content/dirve/MyDrive/Colab Notebooks/package')\n",
    "else:\n",
    "    DIR_PATH = r\"D:\\\\論文實驗\\\\data\\\\dblp\\\\\"\n",
    "    sys.path.append('D:\\\\論文實驗\\\\package')\n",
    "    sys.path.append(\"D:\\\\論文實驗\\\\env\\\\Lib\\\\site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8854303-1b98-414c-a583-a70752f4a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import preprocessingText\n",
    "\n",
    "DIR_PATH = r\"D:\\\\論文實驗\\\\data\\\\amazon\\\\\"\n",
    "DATASET = r\"meta_Software.json\"\n",
    "\n",
    "def checkAttr():\n",
    "    '''\n",
    "        check whether ASIN of the item is existing.\n",
    "        \n",
    "        Result: \n",
    "            all of the items exist ASIN of the properties.\n",
    "    '''\n",
    "    with open(DIR_PATH + DATASET, \"r\") as f:\n",
    "        data = pd.read_json(f, orient=\"records\", typ=\"series\", lines=True)\n",
    "    \n",
    "        for item in data:\n",
    "            if not all(key in item for key in [\"asin\", \"also_view\", \"also_buy\", \"category\", \"price\"]):\n",
    "                print(item)\n",
    "\n",
    "def reduceAttr(output_file):\n",
    "    '''\n",
    "        保留需要的商品屬性, asin, also_view, also_buy, category, price.\n",
    "        also_view和also_buy有多個以上時, 用空白隔開\n",
    "    '''\n",
    "    \n",
    "    with open(DIR_PATH + DATASET, \"r\") as f:\n",
    "        data = pd.read_json(f, orient=\"records\", typ=\"series\", lines=True, dtype={\"category\":list})\n",
    "\n",
    "        output = open(DIR_PATH + output_file, \"w\")\n",
    "        for item in data:\n",
    "            also_view = \" \".join(item[\"also_view\"])\n",
    "            also_buy = \" \".join(item[\"also_buy\"])\n",
    "            category = \" \".join([preprocessingText(string) for string in item[\"category\"]])\n",
    "            price = item[\"price\"][1:] if item[\"price\"] != \"\" and item[\"price\"][0] == \"$\" else \"\"\n",
    "\n",
    "            if also_view and also_buy and category and price:\n",
    "                row = \"{asin},{also_view},{also_buy},{category},{price}\".format(\n",
    "                    asin = item[\"asin\"], \n",
    "                    also_view = also_view, \n",
    "                    also_buy = also_buy, \n",
    "                    category = category, \n",
    "                    price = price.replace(\",\", \"\"))\n",
    "                output.write(row + \"\\n\")\n",
    "        output.close()\n",
    "checkAttr()\n",
    "reduceAttr(\"extraction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f99070-2fa6-44f6-9899-410c600a0ddb",
   "metadata": {},
   "source": [
    "### 需要保留的商品屬性\n",
    "- asin\n",
    "- also_view\n",
    "- also_buy\n",
    "- category\n",
    "- price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793ca8f-f09d-4b68-a210-5c87a9ad58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DIR_PATH + DATASET, \"r\") as f:\n",
    "    data = pd.read_json(f, orient=\"records\", typ=\"series\", lines=True)\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item[\"asin\"] == \"0078605407\":\n",
    "            count += 1\n",
    "            also_view = \" \".join(item[\"also_view\"])\n",
    "            also_buy = \" \".join(item[\"also_buy\"])\n",
    "            category = \" \".join([preprocessingText(string) for string in item[\"category\"]])\n",
    "            price = item[\"price\"][1:] if item[\"price\"] != \"\" and item[\"price\"][0] == \"$\" else \"\"\n",
    "            \n",
    "            print(\"{asin},{also_view},{also_buy},{category},{price}\".format(\n",
    "                    asin = item[\"asin\"], \n",
    "                    also_view = also_view, \n",
    "                    also_buy = also_buy, \n",
    "                    category = category, \n",
    "                    price = str(price)))\n",
    "#print(\"{0}/{1}\".format(count, data.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DIR_PATH + \"extraction.csv\", \"r\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count = count + 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c671ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_items(filename):\n",
    "    dataset = dict()\n",
    "    with open(filename) as file:\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            asin, also_view, also_buy, category, price = line.split(\",\")\n",
    "            dataset[asin] = dict()\n",
    "            dataset[asin][\"also_view\"] = also_view.split(\" \")\n",
    "            dataset[asin][\"also_buy\"] = also_buy.split(\" \")\n",
    "            dataset[asin][\"category\"] = category.split(\" \")\n",
    "            dataset[asin][\"price\"] = float(price)\n",
    "            dataset[asin][\"freq\"] = 1\n",
    "\n",
    "    for asin, attr in dataset.items():\n",
    "        filter_list = []\n",
    "        for substitution in attr[\"also_view\"]:\n",
    "            if substitution in dataset:\n",
    "                filter_list.append(substitution)\n",
    "                dataset[substitution][\"freq\"] += 1\n",
    "\n",
    "        dataset[asin][\"also_view\"] = filter_list\n",
    "\n",
    "        filter_list = []\n",
    "        for complementary in attr[\"also_buy\"]:\n",
    "            if complementary in dataset:\n",
    "                filter_list.append(complementary)\n",
    "                dataset[complementary][\"freq\"] += 1\n",
    "\n",
    "        dataset[asin][\"also_buy\"] = filter_list\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def maxFrequency(filename):\n",
    "    dataset = dict()\n",
    "\n",
    "    with open(filename) as file:\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            asin, also_view, also_buy, category, price = line.split(\",\")\n",
    "            dataset[asin] = dict()\n",
    "            dataset[asin][\"also_view\"] = also_view.split(\" \")\n",
    "            dataset[asin][\"also_buy\"] = also_buy.split(\" \")\n",
    "            dataset[asin][\"freq\"] = 1\n",
    "    \n",
    "    max_asin = \"\"\n",
    "    max_freq = 0\n",
    "\n",
    "    for asin, attr in dataset.items():\n",
    "        filter_list = []\n",
    "        for substitution in attr[\"also_view\"]:\n",
    "            if substitution in dataset:\n",
    "                filter_list.append(substitution)\n",
    "                dataset[substitution][\"freq\"] += 1\n",
    "\n",
    "        dataset[asin][\"also_view\"] = filter_list\n",
    "\n",
    "        filter_list = []\n",
    "        for complementary in attr[\"also_buy\"]:\n",
    "            if complementary in dataset:\n",
    "                filter_list.append(complementary)\n",
    "                dataset[complementary][\"freq\"] += 1\n",
    "\n",
    "        dataset[asin][\"also_buy\"] = filter_list\n",
    "\n",
    "        if dataset[asin][\"freq\"] > max_freq:\n",
    "            max_asin = asin\n",
    "            max_freq = dataset[asin][\"freq\"]\n",
    "\n",
    "    return max_asin\n",
    "\n",
    "\n",
    "def sample_items(dataset:dict, root, num_substituion=0, num_complements=0, picked = []):\n",
    "    \n",
    "    def _bfs_sample(dataset, root, num, relation:str, picked = picked):\n",
    "        \n",
    "        if relation not in ['also_buy', 'also_view']:\n",
    "            raise ValueError(\"Parameter of relation is an error\")\n",
    "\n",
    "        queue = []\n",
    "        if root not in picked:\n",
    "            picked.append(root)\n",
    "        queue.append(root)\n",
    "\n",
    "        while len(queue) != 0 and num > 0:\n",
    "            queue += dataset[root][relation]\n",
    "            \n",
    "            # pop first element\n",
    "            root = queue[0]\n",
    "            del queue[0]\n",
    "\n",
    "            if root not in picked:\n",
    "                picked.append(root)\n",
    "                num -= 1\n",
    "\n",
    "    _bfs_sample(dataset, root, num_substituion, \"also_view\", picked)\n",
    "    _bfs_sample(dataset, root, num_complements, \"also_buy\", picked)\n",
    "    return picked\n",
    "    \n",
    "    \n",
    "# print(\"asin: \" + max_freq_asin)\n",
    "# print(\"also_view: {0}\".format(dataset[max_freq_asin][\"also_view\"]))\n",
    "# print(\"also_buy: {0}\".format(dataset[max_freq_asin][\"also_buy\"]))\n",
    "# print(\"category: {0}\".format(dataset[max_freq_asin][\"category\"]))\n",
    "# print(\"price: {0}\".format(dataset[max_freq_asin][\"price\"]))\n",
    "# print(\"freq: {0}\".format(dataset[max_freq_asin][\"freq\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387dd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = r\"D:\\\\論文實驗\\\\data\\\\amazon\\\\\"\n",
    "FILE = r\"preprocessed_Software.csv\"\n",
    "\n",
    "dataset = read_items(DIR_PATH + FILE)\n",
    "max_freq_asin = maxFrequency(DIR_PATH + FILE) # value of frequency has been removed\n",
    "\n",
    "result = []\n",
    "sample_items(dataset, max_freq_asin, 1, 1, result)\n",
    "print(len(result))\n",
    "\n",
    "with open(DIR_PATH + \"/sample_items.csv\", \"w\") as file:\n",
    "    file.write(\"asin,also_view,also_buy,category,price\\n\")\n",
    "    for asin in result:\n",
    "        file.write(\"{0},{1},{2},{3},{4}\\n\".format(\n",
    "            asin,\n",
    "            \" \".join(dataset[asin][\"also_view\"]),\n",
    "            \" \".join(dataset[asin][\"also_buy\"]),\n",
    "            \" \".join(dataset[asin][\"category\"]),\n",
    "            dataset[asin][\"price\"]\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "02780483269052b0ddef6a1fd82b82d2be0dd99a863ba9a6369e5e299a35d3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
